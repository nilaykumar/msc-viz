#+TITLE: analyzing msc data
#+author: Nilay Kumar
#+date: <2022-03-29 Tue>

# ensure that we export both code and results
#+property: header-args:jupyter-python :exports both :session py :async yes :results raw drawer
#+property: header-args:sh :exports both :results output

TODO:
- check to make sure that all the MSCs are valid (there are some that look like
  49-01 -- what are those?)

Let's begin by importing the MSC data.

#+begin_src jupyter-python
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

from sklearn.manifold import spectral_embedding

filename = 'mar30_data'

df = pd.read_csv(f'data/{filename}.csv')
df = df.rename({'class': 'msc',
           'refclass': 'refmsc'}, axis = 1)
df.drop(df.index[[715]], inplace=True)
#+end_src

#+RESULTS:
:results:
:end:
:end:
:end:

* constructing a weighted graph

The first step in constructing our graph is to get a list of unique MSCs present
in the dataset.

#+begin_src jupyter-python
classes_full = set()

# process the record's classes
for row in df.itertuples():
    cl = row.msc
    clref = row.refmsc
    classes_full.update([s.strip()[1:-1] for s in cl[1:-1].split(',')])
    classes_full.update([s.strip()[1:-1] for s in clref[1:-1].split(',')])

# construct a set of the abbreviated 2-digit mscs
classes_abbrev = set()
for msc in classes_full:
    classes_abbrev.add(msc[0:2])

classes_abbrev = sorted(classes_abbrev)
N = len(classes_abbrev)
print(f'Found N={N} unique 2-digit MSC codes.')
#+end_src

#+RESULTS:
:results:
: Found N=63 unique 2-digit MSC codes.
:end:

Let's construct the corresponding graph with N vertices. Since we're restricting
to 2-digit codes, the number of vertices is small enough that we can feasibly
work with an adjacency matrix. We'll use the set =classes_abbrev= from above as
our dictionary for translating between matrix indexing and the codes.

#+begin_src jupyter-python :file images/heatmap.png
all_msc = list(classes_abbrev)
adj = np.zeros((N, N), dtype = np.int64)
logadj = np.zeros((N, N), dtype = np.float64)
for row in df.itertuples():
    cl = row.msc
    clref = row.refmsc
    refmsc_list = [s.strip()[1:-1] for s in clref[1:-1].split(',')]
    # for each msc associated to the record
    for msc in [s.strip()[1:-1] for s in cl[1:-1].split(',')]:
        msc = msc[0:2]
        # get row index
        i = all_msc.index(msc)
        # for each msc in the references of this record
        for refmsc in refmsc_list:
            refmsc = refmsc[0:2]
            j = all_msc.index(refmsc)
            adj[i][j] += 1
logadj = np.log1p(adj)
symm_logadj = (logadj + logadj.T) / 2
fig = plt.figure()
ax = sns.heatmap(symm_logadj)

# relabel the axes by the 2-digit MSC code
labelsx =  ax.get_xticklabels()
for label in labelsx:
    label.set_text(classes_abbrev[int(label.get_text())])
ax.set_xticklabels(labelsx)
labelsy =  ax.get_yticklabels()
for label in labelsy:
    label.set_text(classes_abbrev[int(label.get_text())])
ax.set_yticklabels(labelsy);
#+end_src

#+RESULTS:
:results:
[[file:images/heatmap.png]]
:end:

This gives us the weighted graph, whose adjacency matrix (or
its elementwse-logarithm, really) is displayed here as a heatmap.
This heatmap already indicates some interesting behavior.


* laplacian eigenmaps

We use =sklearn='s =spectral_embedding=, which uses the technique known as
Laplacian eigenmaps to embed the graph into a relatively low-dimensional
Euclidean space. The embedding is designed to embed vertices connected by
high weight relatively close to one another.

#+begin_src jupyter-python
def lapeig(adj, d = 8):
    embedding = spectral_embedding(adj, n_components = d, random_state = 17, eigen_solver='lobpcg')
    df_embedding = pd.DataFrame(embedding)
    df_embedding['msc'] = classes_abbrev
    return df_embedding.set_index('msc')
#+end_src

#+RESULTS:
:results:
:end:

Let's try embedding our graph into two-dimensional Euclidean space.
#+begin_src jupyter-python
df_2d = lapeig((adj + adj.T)/2, 2)
plt.figure(figsize=(12, 10))
# ax = sns.scatterplot(data = df_2d, x = df_2d[0], y = df_2d[1], hue = df_2d.index)
for row in df_2d.itertuples():
    plt.scatter(row._1, row._2, marker=f'${row.Index}$', s=100)
# the legend is way too long
#legend = ax.get_legend()
#legend.remove()
plt.savefig(f'images/{filename}.png')
#+end_src

#+RESULTS:
:results:
[[file:./.ob-jupyter/9c2828f94be251250a1147be9a3f970932bc2d25.png]]
:end:
:end:
:end:

Is there a natural way to assign height? Perhaps based on popularity? and then
perhaps smoothed out nicely...

What happens when we take the first 3-digits? Should we expand to a
3-dimensional representation?
